% Conclusion

\chapter{Conclusion} % Main chapter title

\label{Conclusion} % For referencing the chapter elsewhere, use \ref{Conclusion}

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content
%\newcommand{\keyword}[1]{\textbf{#1}}
%\newcommand{\tabhead}[1]{\textbf{#1}}
%\newcommand{\code}[1]{\texttt{#1}}
%\newcommand{\code}[1]{\texttt{\hl{#1}}}
%\newcommand{\file}[1]{\texttt{\bfseries#1}}
%\newcommand{\option}[1]{\texttt{\itshape#1}}
%\newcommand{\iBubble}{\textsc{iBubble}}
%\newcommand{\rasp}{\textsc{Raspberry Pi}}
%\newcommand{\vc}{\textsc{VideoCore iv 3D}}
%\newcommand{\cpu}{\textsc{arm cpu}}
%\newcommand{\bcm}{\textsc{bcm2837}}
%\newcommand{\qpu}{\textsc{qpu}}
%\newcommand{\flow}{\textsc{optical flow}}
%\newcommand{\feat}{\textsc{feature}}
%\newcommand{\api}{\textsc{api}}
%\newcommand{\ram}{\textsc{shared ram}}
%\newcommand{\mail}{\textsc{mailbox}}
%\newcommand{\uni}{\textsc{uniform}}

%----------------------------------------------------------------------------------------

\section{Results}

To test this \api{} I compute the \flow{} first using \code{calcOpticalFlowPyrLK()} and then using \code{compute\_lk\_gpu()} - listing~\ref{mainLst}. Running the project with \code{sudo ./optical\_flow\_internship /home/pi/video/video\_out.avi} generates a directory containing three files:
\begin{itemize}
	\item \file{video\_out\_init\_features.jpg} - an image with the initial \feat{}s positions - Figure~\ref{initFeaturesFig}
	\item \file{video\_out\_opt\_flow\_vectors.avi} - a video where \flow{} between each consecutive frames is representing by \textcolor{blue}{blue vectors} - Figure~\ref{opticalFlowFig}
	\item \file{video\_out\_vectors.json} - a \file{json} file containing all the 30 $(d_{x},d_{y})$ values for each frame of the whole \emph{video\_sample}
\end{itemize}

Moreover the terminal displays time processing for each frame of the video. So I am able to compare time when using this two functions.


\subsection{Time Comparison}

\lstset{language=bash,caption={\code{calcOpticalFlowPyrLK} terminal output},basicstyle=\tiny,label=timeOpenCV}
\begin{lstlisting}
mean time per frame: 0.00538982 for 24 frames.
JSON file of vectors of each features at each frames can be found at: /home/pi/video/video_out/video_out_vectors.json

Video with vector representing optical flow has been written at : /home/pi/video/video_out/video_out_opt_flow_vectors.avi

**********************************************************************
**********************************************************************
All videos / frames of: /home/pi/video have been processed !
**********************************************************************
\end{lstlisting}


\lstset{language=bash,caption={\code{compute\_lk\_gpu} terminal output},basicstyle=\tiny,label=timeGPU}
\begin{lstlisting}
mean time per frame: 0.0119438 for 24 frames.
JSON file of vectors of each features at each frames can be found at: /home/pi/video/video_out/video_out_vectors.json

Video with vector representing optical flow has been written at : /home/pi/video/video_out/video_out_opt_flow_vectors.avi

**********************************************************************
**********************************************************************
All videos / frames of: /home/pi/video have been processed !
**********************************************************************
\end{lstlisting}

Listings~\ref{timeOpenCV} and~\ref{timeGPU} display the \emph{mean time per frame} to compute \flow{}:
\begin{itemize}
	\item \option{0.0054s} with \code{calcOpticalFlowPyrLK()}
	\item \option{0.0119s} with \code{compute\_lk\_gpu()}
\end{itemize}

Using \vc{} is twice slower than \emph{OpenCV} function but this will release \keyword{CPU} ressources and theoretically \option{0.0119s} per frame could carry a ratio around \keyword{80 frames per second} which is promising for \iBubble{}'s visual tracking system.


\subsection{Values Comparison}

\noindent\begin{minipage}{.45\textwidth}
\begin{lstlisting}[caption={\code{calcOpticalFlowPyrLK} values},frame=tlrb,basicstyle=\tiny,label=openVal]{Name}
"number": "1",
"vectors": {
	"feature 1": "[0.0529022, 1.44458]",
	"feature 2": "[0.0597687, 1.52913]",
	"feature 3": "[0.0342407, 1.41058]",
	"feature 4": "[0.112976, 1.22267]",
	"feature 5": "[0.0827942, 1.44588]",
	"feature 6": "[0.248459, 1.40508]",
	"feature 7": "[-0.015213, 1.4809]",
	"feature 8": "[0, 0]",
	"feature 9": "[0.0228882, 1.63636]",
	"feature 10": "[0.0141602, 1.18526]",
	"feature 11": "[0.168091, 1.44987]",
	"feature 12": "[0.13475, 1.66971]",
	"feature 13": "[0, 0]",
	"feature 14": "[0.00767517, 1.44165]",
	"feature 15": "[0, 0]",
	"feature 16": "[0.0722351, 1.42871]",
	"feature 17": "[0.102554, 1.21632]",
	"feature 18": "[-0.010025, 1.1138]",
	"feature 19": "[0, 0]",
	"feature 20": "[0.0588074, 1.37506]",
	"feature 21": "[0, 0]",
	"feature 22": "[0, 0]",
	"feature 23": "[0, 0]",
	"feature 24": "[0, 0]",
	"feature 25": "[0, 0]",
	"feature 26": "[0, 0]",
	"feature 27": "[-0.0355682, 1.50957]",
	"feature 28": "[0, 0]",
	"feature 29": "[0, 0]",
	"feature 30": "[0, 0]"
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.45\textwidth}
	\begin{lstlisting}[caption={\code{compute\_lk\_gpu} values},frame=tlrb,basicstyle=\tiny,label=gpuVal]{Name}
"number": "1",
"vectors": {
	"feature 1": "[0.051239, 1.49907]",
	"feature 2": "[0.0566864, 1.49538]",
	"feature 3": "[0.0485229, 1.35619]",
	"feature 4": "[0.117294, 1.25969]",
	"feature 5": "[0.0852509, 1.44672]",
	"feature 6": "[0.166031, 1.45792]",
	"feature 7": "[0.0622253, 1.5038]",
	"feature 8": "[0.0437317, 1.45819]",
	"feature 9": "[0.117691, 1.69427]",
	"feature 10": "[0.00265503, 1.25769]",
	"feature 11": "[0.241287, 1.31388]",
	"feature 12": "[0.139465, 1.62927]",
	"feature 13": "[0.129959, 1.47935]",
	"feature 14": "[0.12989, 1.47667]",
	"feature 15": "[0.0406952, 1.49666]
	"feature 16": "[0.094986, 1.3511]",
	"feature 17": "[0.0591583, 1.27177]",
	"feature 18": "[0.0367737, 1.13118]",
	"feature 19": "[0.0540619, 1.21773]",
	"feature 20": "[0.158203, 1.45867]",
	"feature 21": "[0.0509186, 1.89022]",
	"feature 22": "[0.0492096, 1.49521]",
	"feature 23": "[0.295776, 1.60911]",
	"feature 24": "[0.17981, 1.46049]",
	"feature 25": "[0.0469666, 1.3327]",
	"feature 26": "[0.105698, 1.47306]",
	"feature 27": "[0.115067, 1.43921]",
	"feature 28": "[0.0691986, 1.4396]",
	"feature 29": "[0.0128326, 1.17252]",
	"feature 30": "[-0.0117493, 1.12878]"
\end{lstlisting}
\end{minipage}

Listings~\ref{openVal} and~\ref{gpuVal} display the \keyword{displacement values} for each \feat{} - $[d_{y},d_{x}]$ - between the first and the second frame of the \emph{video\_sample}. Those listings are taken from the \file{json} file and provide:
\begin{itemize}
	\item first $d_{y}$ -- the displacement along \option{column-axis}
	\item then $d_{x}$ -- the displacement along \option{row-axis}
\end{itemize}

These values corresponding to the \flow{} between the first two frames - Figures~\ref{initFeaturesFig} and~\ref{secondFeaturesFig} - of the \emph{video\_sample}.

The displacement between those figures is mainly \option{vertical} - Figure~\ref{opticalFlowFig}. So the resulting displacement values from \code{compute\_lk\_gpu()} match well with values from \code{calcOpticalFlowPyrLK()}. We clearly identify the \option{vertical} trend of the \flow. It would even appear that the \emph{OpenCV} function is optimized not to make iterations when displacement is small in vue of the several $[0,0]$ displacement values.
%----------------------------------------------------------------------------------------

\section{Possibilities}

As of the writing of this report, a part of the Lucas-Kanade method was still in development. This part called \emph{Gaussian Pyramid} is a way to estimate large displacement - large values of $(d_{x},d_{y})$ - between two frames.

Inputs are still \textcolor{blue}{$firstFrame$}, \textcolor{red}{$secondFrame$} and \file{int} $featuresArray[2][30]$. The \emph{Gaussian Pyramid} algorithm is invoked before displacement computation section~\ref{dispComp}. This algorithm provides approached values of $(d_{x},d_{y})$ for each feature. Those values are then injected on the first iteration of displacement computation - Figure~\ref{algoFig}.

\subsection{Pyramid Algorithm}

This algorithm is applied to both \textcolor{blue}{firstFrame} and \textcolor{red}{secondFrame}. At the end we get two $(118\times 178) matrices$.


\subsubsection{First step: first convolution}

The first step is to convolve the input $(240\times 360) frame$ by a $(3\times 3) kernel$. The result is a $(238\times 358) convolved$ frame:

\vspace{5mm}

\noindent\begin{minipage}{.3\textwidth}
	\option{Initial frame}
\[
\begin{bmatrix}

initVal_{0,0} & initVal_{0,1} & \ldots & \ldots & initVal_{0,359}\\

initVal_{1,0} & \ddots & \ldots & \ldots & initVal_{1,359}\\

\vdots & \ldots & \ddots & \ldots & \vdots\\

\vdots & \ldots & \ldots & \ddots & \vdots\\

initVal_{239,0} & \ldots & \ldots  & \ldots & initVal_{239,359}

\end{bmatrix}_{240\times 360}
\]
\end{minipage}\hfill
\begin{minipage}{.3\textwidth}
	\option{Gaussian~$3\times 3$ kernel}
\[
\begin{bmatrix}

1 & 2 & 1\\

2 & 4 & 2\\

1 & 2 & 1\\

\end{bmatrix}_{3\times 3 kernel}
\]
\end{minipage}

\vspace{5mm}

\option{Resulting convolved frame}
\[
\begin{bmatrix}

ConvVal_{0,0} & ConvVal_{0,1} & \ldots & \ldots & ConvVal_{0,357}\\

ConvVal_{1,0} & \ddots & \ldots & \ldots & ConvVal_{1,357}\\

\vdots & \ldots & \ddots & \ldots & \vdots\\

\vdots & \ldots & \ldots & \ddots & \vdots\\

ConvVal_{237,0} & \ldots & \ldots  & \ldots & ConvVal_{237,357}

\end{bmatrix}_{238\times 358}
\]

\vspace{5mm}



\subsubsection{Second step: double convolution}

The second step is to convolve the $(238\times 358) convolved$ frame by the same $(3\times 3) kernel$. The result is a $(236\times 356)double-convolved$ frame:

\vspace{5mm}

\noindent\begin{minipage}{.3\textwidth}
	\option{Convolved frame}
\[
\begin{bmatrix}

ConvVal_{0,0} & ConvVal_{0,1} & \ldots & \ldots & ConvVal_{0,357}\\

ConvVal_{1,0} & \ddots & \ldots & \ldots & ConvVal_{1,357}\\

\vdots & \ldots & \ddots & \ldots & \vdots\\

\vdots & \ldots & \ldots & \ddots & \vdots\\

ConvVal_{237,0} & \ldots & \ldots  & \ldots & ConvVal_{237,357}

\end{bmatrix}_{238\times 358}
\]
\end{minipage}\hfill
\begin{minipage}{.3\textwidth}
	\option{Gaussian~$3\times 3$ kernel}
\[
\begin{bmatrix}

1 & 2 & 1\\

2 & 4 & 2\\

1 & 2 & 1\\

\end{bmatrix}_{3\times 3 kernel}
\]
\end{minipage}

\vspace{5mm}


\option{Resulting double-convolved frame}
\[
\begin{bmatrix}

doubleConvVal_{0,0} & doubleConvVal_{0,1} & \ldots & \ldots & doubleConvVal_{0,355}\\

doubleConvVal_{1,0} & \ddots & \ldots & \ldots & doubleConvVal_{1,355}\\

\vdots & \ldots & \ddots & \ldots & \vdots\\

\vdots & \ldots & \ldots & \ddots & \vdots\\

doubleConvVal_{235,0} & \ldots & \ldots  & \ldots & doubleConvVal_{117,355}

\end{bmatrix}_{236\times 356}
\]

\vspace{5mm}



\subsubsection{Final step: extraction}

The final step is to get a $(118\times 178)extracted$-frame from the $(236\times 356)double-convolved$ frame:

\vspace{5mm}
\option{Final extracted-frame from double-convolved frame}
\[
\begin{bmatrix}

doubleConvVal_{0,0} & doubleConvVal_{0,2} & \ldots & \ldots & doubleConvVal_{0,354}\\

doubleConvVal_{2,0} & \ddots & \ldots & \ldots & doubleConvVal_{2,354}\\

\vdots & \ldots & \ddots & \ldots & \vdots\\

\vdots & \ldots & \ldots & \ddots & \vdots\\

doubleConvVal_{234,0} & \ldots & \ldots  & \ldots & doubleConvVal_{234,354}

\end{bmatrix}_{118\times 178}
\]


\subsection{Optical flow algorithm}

Once we get the two $(118\times 178)extracted$-matrices from \textcolor{blue}{firstFrame} and \textcolor{red}{secondFrame}, we apply the \flow{} algorithm to these $(118\times 178)extracted$-matrices the same way as in Chapter~\ref{Chapter3}, but with all values from $int featuresArray[2][30]$ divided by two. We get 30 $(d_{x},d_{y})$ approached values of each feature displacement.

Finally we can run the \flow{} algorithm on the $(240\times 360)\textcolor{blue}{firstFrame}$ and $(240\times 360)\textcolor{red}{secondFrame}$. The difference is we start with the approached 30 $(d_{x},d_{y})$ values on the first iteration - Figure~\ref{algoFig}. As a result we can manage \flow{} computation for large movements with less iterations and get accurate values.


\subsection{Ongoing status}

At the time of concluding this report all the memory layout - \emph{grad\_MemLayout} - was in place to integrate the \emph{Pyramid Algorithm}.

In \file{grad.h} file - Appendice~\ref{AppendixG} - I defined \ram{} memory spaces for:
\begin{itemize}
	\item \code{convolution} and \code{extraction} \enquote{\file{.bin files}}
	\item additionnal \uni{}s
	\item results from \enquote{\file{.bin files}} execution on \qpu{}s
	\item all these new addresses are stored inside \code{grad\_VCptrsArray[]} section~\ref{gradClbl}
	\item I also wrote all the new functions prototypes
\end{itemize}

The last part will be to write \enquote{\file{.asm}} files containing the \code{convolution}, \code{extraction} and \code{optical flow} code-to-execute on \vc{} in order to get these approached $(d_{x},d_{y})$ values.
%----------------------------------------------------------------------------------------

\subsection{Difficulties experienced}

During my internship I faced several difficulties that I will try to summarize.

First of all, at the beginning my subject was a hazy topic to me. I have never programmed any \keyword{GPU} before and documentation about this kind of processor is a well-kept secret by companies . It took me time to understand what I had to do. I had to acquire a lot of information in a little time just to start some easy steps as a \file{helloworld} program.

Moreover, I was not used to platform such as \file{github}. I discovered a wonderful example of collaboration on interesting projects without which I couldn't get on with my tasks. I had gaps in Embedded Linux development or even in GNU/Linux. I didn't have enough tools such as a standard developping environment. I didn't use \emph{Vim} editor or I didn't know well the \emph{command line}, \emph{GCC/G++} compiler, or \emph{Linux} architecture.

On a hardware point of view I struggled a lot with the \vc{}'s features. For instance, I found out one day that \qpu{} doesn't have a simple \code{div} operation in its instructions set and that made me change the way I wanted to implement the algorithm. Every little \option{assembly} program that compiled and run was a great victory for me.

Nevertheless, I succeed to overcome those challenges thanks to my good background gained at \deptname{}, the kindness of \groupname{} team and my strong willingness.














