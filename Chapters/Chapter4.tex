% Conclusion

\chapter{Conclusion} % Main chapter title

\label{Conclusion} % For referencing the chapter elsewhere, use \ref{Conclusion}

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content
%\newcommand{\keyword}[1]{\textbf{#1}}
%\newcommand{\tabhead}[1]{\textbf{#1}}
%\newcommand{\code}[1]{\texttt{#1}}
%\newcommand{\code}[1]{\texttt{\hl{#1}}}
%\newcommand{\file}[1]{\texttt{\bfseries#1}}
%\newcommand{\option}[1]{\texttt{\itshape#1}}
%\newcommand{\iBubble}{\textsc{iBubble}}
%\newcommand{\rasp}{\textsc{Raspberry Pi}}
%\newcommand{\vc}{\textsc{VideoCore iv 3D}}
%\newcommand{\cpu}{\textsc{arm cpu}}
%\newcommand{\bcm}{\textsc{bcm2837}}
%\newcommand{\qpu}{\textsc{qpu}}
%\newcommand{\flow}{\textsc{optical flow}}
%\newcommand{\feat}{\textsc{feature}}
%\newcommand{\api}{\textsc{api}}
%\newcommand{\ram}{\textsc{shared ram}}
%\newcommand{\mail}{\textsc{mailbox}}
%\newcommand{\uni}{\textsc{uniform}}

%----------------------------------------------------------------------------------------

\section{Results}

To test this \api{} I compute the \flow{} first using \code{calcOpticalFlowPyrLK()} and then using \code{compute\_lk\_gpu()}: listing~\ref{mainLst}. Running the project with \code{sudo ./optical\_flow\_internship /home/pi/video/video\_out.avi} generates a directory containing three files:
\begin{itemize}
	\item \file{video\_out\_init\_features.jpg}: an image containing the initial \feat{}s positions - Figure~\ref{initFeaturesFig}
	\item \file{video\_out\_opt\_flow\_vectors.avi}: a video where \flow{} between each consecutive frames is representing by \textcolor{blue}{blue vectors} - Figure~\ref{opticalFlowFig}
	\item \file{video\_out\_vectors.json}: a \file{json} file containing all the 30 $(d_{x},d_{y})$ values for each frame of the whole \emph{video\_sample}
\end{itemize}

Moreover the terminal displays time processing for each frame of the video. So I am able to compare time when using this two functions.


\subsection{Time Comparison}

\lstset{language=bash,caption={\code{calcOpticalFlowPyrLK} terminal output},basicstyle=\tiny,label=timeOpenCV}
\begin{lstlisting}
mean time per frame: 0.00538982 for 24 frames.
JSON file of vectors of each features at each frames can be found at: /home/pi/video/video_out/video_out_vectors.json

Video with vector representing optical flow has been written at : /home/pi/video/video_out/video_out_opt_flow_vectors.avi

**********************************************************************
**********************************************************************
All videos / frames of: /home/pi/video have been processed !
**********************************************************************
\end{lstlisting}


\lstset{language=bash,caption={\code{compute\_lk\_gpu} terminal output},basicstyle=\tiny,label=timeGPU}
\begin{lstlisting}
mean time per frame: 0.0119438 for 24 frames.
JSON file of vectors of each features at each frames can be found at: /home/pi/video/video_out/video_out_vectors.json

Video with vector representing optical flow has been written at : /home/pi/video/video_out/video_out_opt_flow_vectors.avi

**********************************************************************
**********************************************************************
All videos / frames of: /home/pi/video have been processed !
**********************************************************************
\end{lstlisting}



\subsection{Values Comparison}

\noindent\begin{minipage}{.45\textwidth}
\begin{lstlisting}[caption={\code{calcOpticalFlowPyrLK} values},frame=tlrb,basicstyle=\tiny]{Name}
"number": "1",
"vectors": {
	"feature 1": "[0.0529022, 1.44458]",
	"feature 2": "[0.0597687, 1.52913]",
	"feature 3": "[0.0342407, 1.41058]",
	"feature 4": "[0.112976, 1.22267]",
	"feature 5": "[0.0827942, 1.44588]",
	"feature 6": "[0.248459, 1.40508]",
	"feature 7": "[-0.015213, 1.4809]",
	"feature 8": "[0, 0]",
	"feature 9": "[0.0228882, 1.63636]",
	"feature 10": "[0.0141602, 1.18526]",
	"feature 11": "[0.168091, 1.44987]",
	"feature 12": "[0.13475, 1.66971]",
	"feature 13": "[0, 0]",
	"feature 14": "[0.00767517, 1.44165]",
	"feature 15": "[0, 0]",
	"feature 16": "[0.0722351, 1.42871]",
	"feature 17": "[0.102554, 1.21632]",
	"feature 18": "[-0.010025, 1.1138]",
	"feature 19": "[0, 0]",
	"feature 20": "[0.0588074, 1.37506]",
	"feature 21": "[0, 0]",
	"feature 22": "[0, 0]",
	"feature 23": "[0, 0]",
	"feature 24": "[0, 0]",
	"feature 25": "[0, 0]",
	"feature 26": "[0, 0]",
	"feature 27": "[-0.0355682, 1.50957]",
	"feature 28": "[0, 0]",
	"feature 29": "[0, 0]",
	"feature 30": "[0, 0]"
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.45\textwidth}
\begin{lstlisting}[caption={\code{compute\_lk\_gpu} values},frame=tlrb,basicstyle=\tiny]{Name}
"number": "1",
"vectors": {
	"feature 1": "[0.051239, 1.49907]",
	"feature 2": "[0.0566864, 1.49538]",
	"feature 3": "[0.0485229, 1.35619]",
	"feature 4": "[0.117294, 1.25969]",
	"feature 5": "[0.0852509, 1.44672]",
	"feature 6": "[0.166031, 1.45792]",
	"feature 7": "[0.0622253, 1.5038]",
	"feature 8": "[0.0437317, 1.45819]",
	"feature 9": "[0.117691, 1.69427]",
	"feature 10": "[0.00265503, 1.25769]",
	"feature 11": "[0.241287, 1.31388]",
	"feature 12": "[0.139465, 1.62927]",
	"feature 13": "[0.129959, 1.47935]",
	"feature 14": "[0.12989, 1.47667]",
	"feature 15": "[0.0406952, 1.49666]",
	"feature 16": "[0.094986, 1.3511]",
	"feature 17": "[0.0591583, 1.27177]",
	"feature 18": "[0.0367737, 1.13118]",
	"feature 19": "[0.0540619, 1.21773]",
	"feature 20": "[0.158203, 1.45867]",
	"feature 21": "[0.0509186, 1.89022]",
	"feature 22": "[0.0492096, 1.49521]",
	"feature 23": "[0.295776, 1.60911]",
	"feature 24": "[0.17981, 1.46049]",
	"feature 25": "[0.0469666, 1.3327]",
	"feature 26": "[0.105698, 1.47306]",
	"feature 27": "[0.115067, 1.43921]",
	"feature 28": "[0.0691986, 1.4396]",
	"feature 29": "[0.0128326, 1.17252]",
	"feature 30": "[-0.0117493, 1.12878]"
\end{lstlisting}
\end{minipage}


%----------------------------------------------------------------------------------------

\section{Possibilities}

As of the writing of this report, a part of the Lucas-Kanade method was still in development. This part called \emph{Gaussian Pyramids} is a way to estimate large displacement - large values of $(d_{x},d_{y})$ - between two frames.

Inputs are still \textcolor{blue}{firstFrame}, \textcolor{red}{secondFrame} and \file{int} $featuresArray[2][30]$. The \emph{Gaussian Pyramids} algorithm is invoked before displacement computation section~\ref{dispComp}. This algorithm provides approached values of $(d_{x},d_{y})$ for each feature. Those values are injected on the first iteration of displacement computation - Figure~\ref{algoFig}.

\subsection{Pyramid Algorithm}

This algorithm is applied to both \textcolor{blue}{firstFrame} and \textcolor{red}{secondFrame}. At the end we get two $(118\times 178)$ matrices.


\subsubsection{First step: first convolution}

The first step is to convolve the input $(240\times 360)$ frame by a $(3\times 3)$ kernel. The result is a $(238\times 358)$ convoluted frame:

\noindent\begin{minipage}{.3\textwidth}
Initial frame
\[
\begin{bmatrix}

initVal_{0,0} & initVal_{0,1} & \ldots & \ldots & initVal_{0,359}\\

initVal_{1,0} & \ddots & \ldots & \ldots & initVal_{1,359}\\

\vdots & \ldots & \ddots & \ldots & \vdots\\

\vdots & \ldots & \ldots & \ddots & \vdots\\

initVal_{239,0} & \ldots & \ldots  & \ldots & initVal_{239,359}

\end{bmatrix}_{240\times 360}
\]
\end{minipage}\hfill
\begin{minipage}{.3\textwidth}
Gaussian~$3\times 3$ kernel
\[
\begin{bmatrix}

1 & 2 & 1\\

2 & 4 & 2\\

1 & 2 & 1\\

\end{bmatrix}_{3\times 3 kernel}
\]
\end{minipage}

\vspace{10mm}

Resulting convoluted frame
\[
\begin{bmatrix}

ConvVal_{0,0} & ConvVal_{0,1} & \ldots & \ldots & ConvVal_{0,357}\\

ConvVal_{1,0} & \ddots & \ldots & \ldots & ConvVal_{1,357}\\

\vdots & \ldots & \ddots & \ldots & \vdots\\

\vdots & \ldots & \ldots & \ddots & \vdots\\

ConvVal_{237,0} & \ldots & \ldots  & \ldots & ConvVal_{237,357}

\end{bmatrix}_{238\times 358}
\]




\subsubsection{Second step: double convolution}

The second step is to convolve the convoluted $(238\times 358)$ frame by the same $(3\times 3)$ kernel. The result is a $(236\times 356)$ double convoluted frame:

\vspace{10mm}

\noindent\begin{minipage}{.3\textwidth}
Convoluted frame
\[
\begin{bmatrix}

ConvVal_{0,0} & ConvVal_{0,1} & \ldots & \ldots & ConvVal_{0,357}\\

ConvVal_{1,0} & \ddots & \ldots & \ldots & ConvVal_{1,357}\\

\vdots & \ldots & \ddots & \ldots & \vdots\\

\vdots & \ldots & \ldots & \ddots & \vdots\\

ConvVal_{237,0} & \ldots & \ldots  & \ldots & ConvVal_{237,357}

\end{bmatrix}_{238\times 358}
\]
\end{minipage}\hfill
\begin{minipage}{.3\textwidth}
Gaussian~$3\times 3$ kernel
\[
\begin{bmatrix}

1 & 2 & 1\\

2 & 4 & 2\\

1 & 2 & 1\\

\end{bmatrix}_{3\times 3 kernel}
\]
\end{minipage}

\vspace{10mm}


Resulting double convoluted frame
\[
\begin{bmatrix}

doubleConvVal_{0,0} & doubleConvVal_{0,1} & \ldots & \ldots & doubleConvVal_{0,355}\\

doubleConvVal_{1,0} & \ddots & \ldots & \ldots & doubleConvVal_{1,355}\\

\vdots & \ldots & \ddots & \ldots & \vdots\\

\vdots & \ldots & \ldots & \ddots & \vdots\\

doubleConvVal_{235,0} & \ldots & \ldots  & \ldots & doubleConvVal_{117,355}

\end{bmatrix}_{236\times 356}
\]



\subsubsection{Final step: extraction}

The final step is to extract a $(118\times 178)$ frame from the double $(236\times 356)$ convoluted frame:

\vspace{10mm}
Final extracted frame from double convoluted frame
\[
\begin{bmatrix}

doubleConvVal_{0,0} & doubleConvVal_{0,2} & \ldots & \ldots & doubleConvVal_{0,354}\\

doubleConvVal_{2,0} & \ddots & \ldots & \ldots & doubleConvVal_{2,354}\\

\vdots & \ldots & \ddots & \ldots & \vdots\\

\vdots & \ldots & \ldots & \ddots & \vdots\\

doubleConvVal_{234,0} & \ldots & \ldots  & \ldots & doubleConvVal_{234,354}

\end{bmatrix}_{118\times 178}
\]


\subsection{Optical flow algorithm}

Once we get the two $(118\times 178) extracted-matrices$ from \textcolor{blue}{firstFrame} and \textcolor{red}{secondFrame}, we apply the \flow{} algorithm to these $extracted-matrices$ the same way as in Chapter~\ref{Chapter3}, but with all values from $int featuresArray[2][30]$ divided by two. We get 30 $(d_{x},d_{y})$ approached values of each feature displacement.

Finally we can run the \flow{} algorithm on the $(240\times 360)$ \textcolor{blue}{firstFrame} and \textcolor{red}{secondFrame}. The difference is we start with the approached 30 $(d_{x},d_{y})$ values on the first iteration - Figure~\ref{algoFig}. As a result we can't manage \flow{} computation for large movements with less iterations and get accurate values.


\subsection{Ongoing status}

At the time of concluding this report all the memory layout - \emph{grad\_MemLayout} - was in place to integrate the \emph{Pyramid Algorithm}.

In \file{grad.h} file - Appendice~\ref{AppendixG} - I defined \ram{} memory spaces for \code{convolution} and \code{extraction} code, additionnal \uni{}s and results from \qpu{}s. All those new addresses are stored inside \code{grad\_VCptrsArray[]} section~\ref{gradClbl}. I also wrote all the new functions prototypes.

The last part will be to write \file{.asm} files containing the \code{convolution}, \code{extraction} and \code{optical flow} code for the convolved frames.
%----------------------------------------------------------------------------------------

